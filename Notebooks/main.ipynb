{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g37NuioNl0ws"
      },
      "source": [
        "# Dataset Summary and Objective\n",
        "\n",
        "## 1. Dataset Fields:\n",
        "- **Name:** Patient's name (can be anonymized or excluded for modeling).\n",
        "- **Age:** Patient's age.\n",
        "- **Gender:** Patient's gender (male/female).\n",
        "- **Blood Type:** Patient's blood type (e.g., A, B, AB, O).\n",
        "- **Medical Condition:** Patient's medical issue (e.g., cancer, obesity, diabetes).\n",
        "- **Date of Admission:** The date the patient was admitted to the hospital.\n",
        "- **Doctor:** The attending doctor.\n",
        "- **Hospital:** Hospital information.\n",
        "- **Insurance Provider:** Patient's insurance company.\n",
        "- **Billing Amount:** Total hospital expenses.\n",
        "- **Room Number:** Hospital room number.\n",
        "- **Admission Type:** Type of hospital admission (e.g., urgent, elective).\n",
        "- **Discharge Date:** The date the patient was discharged.\n",
        "- **Medication:** Prescribed medication.\n",
        "- **Test Results:** Health test results (Normal, Inconclusive, Abnormal).\n",
        "\n",
        "## 2. Project Objective:\n",
        "- Build a classification model to predict test results (Normal, Inconclusive, Abnormal).\n",
        "- Prioritize critical health cases by predicting health conditions early.\n",
        "- Analyze the impact of insurance costs, medication, and admission type on test results.\n",
        "\n",
        "## 3. Machine Learning Methods to Apply:\n",
        "- **Logistic Regression:** A simple and explainable classification model.\n",
        "- **Decision Trees:** To identify the most important features.\n",
        "- **Support Vector Machines (SVM):** For learning complex classification boundaries.\n",
        "\n",
        "## 4. Expected Outcomes:\n",
        "- Develop a classification model to predict critical health conditions effectively.\n",
        "- Improve the accuracy of test result predictions to support clinical decision-making.\n",
        "- Provide insights to optimize medical costs and enhance healthcare outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVaVvjE4l0wv"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e8HOjGuOl0wx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import joblib\n",
        "import os\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehjWtWpPl0wz"
      },
      "source": [
        "# Data Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "73-Vubvil0w1",
        "outputId": "12024f9e-0901-4a18-aa4d-beddd3f65516"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Analysis-of-Healthcare/Datasets/healthcare_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3450391770>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Analysis-of-Healthcare/Datasets/healthcare_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Analysis-of-Healthcare/Datasets/healthcare_dataset.csv'"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv(\"Analysis-of-Healthcare/Datasets/healthcare_dataset.csv\")\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs3T8rbJl0w4"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWyHWg3Nl0w5"
      },
      "source": [
        "## Basic Stats to Understand Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwderHyCl0w6"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVAgUlQCl0w7"
      },
      "outputs": [],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODPYFbLGl0w8"
      },
      "source": [
        "* Necessary steps to do:\n",
        "    - Name column has to be prepared properly\n",
        "    - Data of Admission & Discharge Date has to be converted to the Date Time type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h03SUyzbl0w8"
      },
      "outputs": [],
      "source": [
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrWwVmW6l0w9"
      },
      "source": [
        "### Name Column trasformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbbCyHfGl0w9"
      },
      "outputs": [],
      "source": [
        "def normalize_name(name):\n",
        "    return ' '.join(word.capitalize() for word in name.split())\n",
        "\n",
        "dataset['Name'] = dataset['Name'].apply(normalize_name)\n",
        "\n",
        "# Check\n",
        "dataset['Name'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u5Y4xmIl0w-"
      },
      "source": [
        "### Type conversetion of Date related columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXPrOjPel0w-"
      },
      "outputs": [],
      "source": [
        "dataset['Date of Admission'] = pd.to_datetime(dataset['Date of Admission'])\n",
        "dataset['Discharge Date'] = pd.to_datetime(dataset['Discharge Date'])\n",
        "\n",
        "#Check\n",
        "for i in [dataset['Discharge Date'], dataset['Date of Admission']]:\n",
        "    i.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uipvaRdl0w_"
      },
      "source": [
        "## Missing Value Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SoMmPOml0w_"
      },
      "outputs": [],
      "source": [
        "dataset.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGYcGAc3l0w_"
      },
      "source": [
        "* Clear, ðŸ˜‰"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpebADfkl0xA"
      },
      "source": [
        "### Data Distribution Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IevVkL_2l0xA"
      },
      "source": [
        "#### Age Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDH9UNtUl0xA"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Age'].value_counts().index, height = dataset['Age'].value_counts())\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Age Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye6N-XfHl0xB"
      },
      "source": [
        "#### Gender Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ6BIK0Xl0xB"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Gender'].value_counts().index, height = dataset['Gender'].value_counts())\n",
        "ax.set_xlabel('Gender')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Gender Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t7AJDp-l0xC"
      },
      "source": [
        "#### Blood Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLBU1sb7l0xC"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Blood Type'].value_counts().index, height = dataset['Blood Type'].value_counts())\n",
        "ax.set_xlabel('Blood Type')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Blood Type Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EpUU5-sl0xD"
      },
      "source": [
        "#### Medical Condition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9eKkpGdl0xD"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Medical Condition'].value_counts().index, height = dataset['Medical Condition'].value_counts())\n",
        "ax.set_xlabel('Medical Condition')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Medical Condition Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inAiHb5tl0xE"
      },
      "source": [
        "#### Doctor Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUhQ4hubl0xE"
      },
      "outputs": [],
      "source": [
        "len(dataset['Doctor'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxuPnZQOl0xF"
      },
      "source": [
        "#### Hostpital Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CeQIHQll0xF"
      },
      "outputs": [],
      "source": [
        "len(dataset['Hospital'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT8szx7fl0xF"
      },
      "source": [
        "#### Insurance Provider Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8OREWTsl0xG"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Insurance Provider'].value_counts().index, height = dataset['Insurance Provider'].value_counts())\n",
        "ax.set_xlabel('Insurance Provider')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Insurance Provider Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u-NzsWfl0xH"
      },
      "source": [
        "#### Room Number Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phrSBmMHl0xH"
      },
      "outputs": [],
      "source": [
        "len(dataset['Room Number'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODI56ylOl0xH"
      },
      "source": [
        "#### Admission Type Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_WnKXCbl0xI"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Admission Type'].value_counts().index, height = dataset['Admission Type'].value_counts())\n",
        "ax.set_xlabel('Admission Type')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Admission Type Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWhbrDC9l0xI"
      },
      "source": [
        "#### Test Results Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOSM1Vj2l0xI"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Test Results'].value_counts().index, height = dataset['Test Results'].value_counts())\n",
        "ax.set_xlabel('Test Results')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Test Results Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY7zila6l0xX"
      },
      "source": [
        "#### Medication Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0SL8_BYl0xX"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "ax.bar(x = dataset['Medication'].value_counts().index, height = dataset['Medication'].value_counts())\n",
        "ax.set_xlabel('Medication')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title(\"Medication Distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kldzq4_7l0xY"
      },
      "outputs": [],
      "source": [
        "dataset['Age Group'] = pd.cut(dataset['Age'], bins=[0, 20, 40, 60, 100], labels=['0-20', '20-40', '40-60', '61+'])\n",
        "df = dataset.groupby('Age Group')['Test Results'].agg('count')\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 6))\n",
        "#ax.bar(x=df.index, height=df)\n",
        "sns.barplot(x=df.index, y=df, ax=ax, palette='viridis')\n",
        "ax.set_title(\"Distribution of Test Results in each Age Group\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF-c34Pcl0xZ"
      },
      "source": [
        "- HastalÄ±k TÃ¼rlerine GÃ¶re Ortalama Masraf Analizi:\n",
        "\n",
        "    TÄ±bbi durumlara gÃ¶re ortalama masraf deÄŸerlerini hesaplayÄ±p gÃ¶rselleÅŸtirin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6QVjDfpl0xa"
      },
      "outputs": [],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBiDTIfYl0xa"
      },
      "outputs": [],
      "source": [
        "df = dataset.groupby('Medical Condition')['Billing Amount'].mean()\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(x=df.index, y=df, ax=ax, palette='rocket_r')\n",
        "ax.set_title(\"Average Expense Analysis by Medical Sondition Types\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dh8b4g1l0xb"
      },
      "source": [
        "- AylÄ±k Hasta Kabul Analizi:\n",
        "\n",
        "    GiriÅŸ tarihlerinden ay bilgisi Ã§Ä±karÄ±larak aylÄ±k hasta kabul yoÄŸunluÄŸunu analiz edin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA1PHwAsl0xc"
      },
      "outputs": [],
      "source": [
        "months=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "dataset['Month']=pd.to_datetime(dataset['Date of Admission']).dt.month\n",
        "monthly_counts = dataset['Month'].value_counts().sort_index()\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(x=months, y=monthly_counts, ax=ax, palette='cubehelix')\n",
        "ax.set_title(\"Number of Patient per Month\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vdju30T-l0xc"
      },
      "source": [
        "- Sigorta SaÄŸlayÄ±cÄ±larÄ±na GÃ¶re Billing Amount DaÄŸÄ±lÄ±mÄ±:\n",
        "\n",
        "    Sigorta ÅŸirketlerine gÃ¶re farklÄ± Billing Amount daÄŸÄ±lÄ±mÄ±nÄ± gruplandÄ±rÄ±n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IM4rrsWl0xd"
      },
      "outputs": [],
      "source": [
        "df = dataset.groupby(['Insurance Provider', 'Gender'])['Billing Amount'].mean().reset_index().sort_values(['Insurance Provider', 'Gender'])\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(x='Insurance Provider', y='Billing Amount', hue='Gender', data=df, ax=ax, palette=\"rocket_r\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ikk2Tonsl0xd"
      },
      "source": [
        "- Kabul TÃ¼rÃ¼ne GÃ¶re Hastanede KalÄ±ÅŸ SÃ¼resi Analizi:\n",
        "\n",
        "    Taburcu ve giriÅŸ tarihlerini kullanarak kalÄ±ÅŸ sÃ¼resini hesaplayÄ±n ve giriÅŸ tÃ¼rÃ¼ne gÃ¶re ortalamalarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ_iiYxtl0xe"
      },
      "outputs": [],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aameqqgzl0xf"
      },
      "outputs": [],
      "source": [
        "dataset['los'] = np.subtract(dataset['Discharge Date'], dataset['Date of Admission']).dt.days\n",
        "\n",
        "df = dataset.groupby(['Admission Type'])['los'].agg('mean').reset_index().sort_values('Admission Type')\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(\n",
        "    data=df,\n",
        "    x='Admission Type',\n",
        "    y='los',\n",
        "    ax=ax,\n",
        "    palette=\"magma\"\n",
        ")\n",
        "ax.set_title(\"Analysis of Length of Stay by Admission Type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh4CEPuLl0xf"
      },
      "source": [
        "- Korelasyon Analizi:\n",
        "\n",
        "    Ã–zellikler arasÄ±ndaki korelasyonu analiz ederek anlamlÄ± iliÅŸkileri belirleyin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au-BTJNQl0xg"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.drop(['Age Group', 'Month', 'los'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-u_JX1nl0xg"
      },
      "outputs": [],
      "source": [
        "feature_corr = dataset.corr(numeric_only=True)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.heatmap(data=feature_corr, annot=True, cmap=\"magma\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYmD5XBOl0xg"
      },
      "source": [
        "- Kan GruplarÄ±na GÃ¶re Masraf DaÄŸÄ±lÄ±mÄ±:\n",
        "\n",
        "    Kan gruplarÄ±na gÃ¶re toplam veya ortalama masrafÄ± analiz edin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snl1f56Xl0xh"
      },
      "outputs": [],
      "source": [
        "df = dataset.groupby(['Blood Type'])['Billing Amount'].agg('mean').sort_values(ascending=True)\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(x=df.index, y=df.values, ax=ax, palette='crest')\n",
        "ax.set_title(\"Analysis of Blood Type by Billing Amount\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWsaTj_Ol0xi"
      },
      "source": [
        "* Billing Amount Accordig to the Blood Type per Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUSMlib_l0xi"
      },
      "outputs": [],
      "source": [
        "df = dataset.groupby(['Gender', 'Blood Type'])['Billing Amount'].agg('sum').reset_index().sort_values('Blood Type')\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(data=df, x='Blood Type', y='Billing Amount', hue='Gender', ax=ax, palette='viridis')\n",
        "ax.set_title(\"Billing Amount Accordig to the Blood Type per Gender\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqTKofdhl0xj"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvGl4HIil0xj"
      },
      "source": [
        "* Creating a new field `Admission Duration`:\n",
        "    - Instead of entrance and exit dates of patient, we can calculate Admissin Duration depending on these dates. After with that calculation, we will not need for `Date Of Admission`, `Discharge Date`, `Name`, `Doctor`, `Hospital` columns so, we can drop them. With this operation we can reduce operation cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ourTKtRl0xk"
      },
      "outputs": [],
      "source": [
        "dataset['Admission Duration'] = (dataset['Discharge Date'] - dataset['Date of Admission']).dt.days\n",
        "dataset.drop(['Name', 'Doctor', 'Date of Admission', 'Discharge Date', 'Hospital', 'Room Number'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMfUqtGdl0xk"
      },
      "source": [
        "* Next we need to also convert categorical features into numerical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4zIQ2Bll0xl"
      },
      "outputs": [],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MPlriZ2l0xm"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "dataset['Gender'] = label_encoder.fit_transform(dataset['Gender'])\n",
        "dataset['Blood Type'] = label_encoder.fit_transform(dataset['Blood Type'])\n",
        "dataset['Medical Condition'] = label_encoder.fit_transform(dataset['Medical Condition'])\n",
        "dataset['Insurance Provider'] = label_encoder.fit_transform(dataset['Insurance Provider'])\n",
        "dataset['Admission Type'] = label_encoder.fit_transform(dataset['Admission Type'])\n",
        "dataset['Medication'] = label_encoder.fit_transform(dataset['Medication'])\n",
        "dataset['Test Results'] = label_encoder.fit_transform(dataset['Test Results'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmGbG_63l0xm"
      },
      "outputs": [],
      "source": [
        "#dataset['Gender'] = dataset['Gender'].map({'Male': 1, 'Female': 0})\n",
        "#dataset['Test Results'] = dataset['Test Results'].map({'Normal': 0, 'Abnormal': 1, 'Inconclusive': 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNffXp7Ql0xn"
      },
      "outputs": [],
      "source": [
        "# dataset = pd.get_dummies(\n",
        "    # dataset,\n",
        "    # columns=[\n",
        "        # 'Gender',\n",
        "        # 'Medication',\n",
        "        # 'Blood Type',\n",
        "        # 'Admission Type',\n",
        "        # 'Medical Condition',\n",
        "        # 'Insurance Provider'\n",
        "    # ],\n",
        "    # drop_first=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VooIo2c4l0xn"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwXon32Tl0xo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "dataset[['Age', 'Billing Amount', 'Admission Duration']] = scaler.fit_transform(dataset[['Age', 'Billing Amount', 'Admission Duration']])\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcq39489l0xo"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndhd4mJzl0xp"
      },
      "source": [
        "## Base Model: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxud-fiKl0xp"
      },
      "source": [
        "* Train - Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Bvm1zyl0xq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dataset.drop(columns=['Test Results'])\n",
        "y = dataset['Test Results']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grnmBODWl0xr"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Ã–nem derecesini gÃ¶rselleÅŸtirin\n",
        "feature_importances = model.feature_importances_\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(X.columns, feature_importances)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1ag0UULl0xr"
      },
      "source": [
        "* `Base Model = Logistic Regression`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN7KQm70l0xr"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)\n",
        "log_reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb6Jf5j8l0xs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "y_pred_logreg = log_reg.predict(X_test)\n",
        "\n",
        "score_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "classification_report_logreg = classification_report(y_test, y_pred_logreg)\n",
        "print(classification_report_logreg)\n",
        "print(\"------------------------------------------\")\n",
        "confusion_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)\n",
        "print(confusion_matrix_logreg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzfIec1cl0xs"
      },
      "source": [
        "* According to the report and confusion matrix, we can clearly say that model is working to predict randomly so, ``accuracy is %34``. For a base model, it's too poor.\n",
        "* Also this consequence can be seen from confusion matrix, many instance of class have been classified wrong.\n",
        "* The reason why the model is so low that it's because of linear model structure, because our target variable descleares 3 kinds of class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDgfmgr8l0xt"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmNuwLM5l0xt"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_test)\n",
        "\n",
        "classification_report_rfc = classification_report(y_test, y_pred_rf)\n",
        "print(classification_report_rfc)\n",
        "print(\"_----------------------------------_\")\n",
        "confusion_matrix_rfc = confusion_matrix(y_test, y_pred_rf)\n",
        "print(confusion_matrix_rfc)\n",
        "print(\"_----------------------------------_\")\n",
        "score_rfc = rnd_clf.score(X_test, y_test)\n",
        "print(score_rfc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP-1L7cHl0xu"
      },
      "source": [
        "### Hyperparameter Tuning for RFC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHT_la6Fl0xu"
      },
      "outputs": [],
      "source": [
        "best_rf_model_file = os.path.join('../Models', 'best_rf_model.pkl')\n",
        "\n",
        "if os.path.exists(best_rf_model_file):\n",
        "    best_rf_model = joblib.load(best_rf_model_file)\n",
        "else:\n",
        "    print(\"Training has been started...\")\n",
        "    rnd_clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],        # AÄŸaÃ§ sayÄ±sÄ±\n",
        "        'max_depth': [None, 10, 20, 30],       # Maksimum derinlik\n",
        "        'min_samples_split': [2, 5, 10],       # DÃ¼ÄŸÃ¼mlerin bÃ¶lÃ¼nmesi iÃ§in minimum Ã¶rnek sayÄ±sÄ±\n",
        "        'min_samples_leaf': [1, 2, 4],          # Yaprak dÃ¼ÄŸÃ¼mdeki minimum Ã¶rnek sayÄ±sÄ±\n",
        "        'bootstrap': [True, False]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=rnd_clf,\n",
        "                               param_grid=param_grid,\n",
        "                               cv=5,\n",
        "                               scoring='accuracy',\n",
        "                               verbose=2,\n",
        "                               n_jobs=-1)\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    #Saving the best model\n",
        "    best_rf_model = grid_search.best_estimator_\n",
        "    joblib.dump(best_rf_model, best_rf_model_file)\n",
        "    print(\"Best model has been saved.\")\n",
        "\n",
        "# En iyi parametreler ve skor\n",
        "if 'grid_search' in locals():\n",
        "    print(\"Best parameters: \", grid_search.best_params_)\n",
        "    print(\"Best Score: \", grid_search.best_score_)\n",
        "\n",
        "y_pred_rfc_tuned = best_rf_model.predict(X_test)\n",
        "\n",
        "# Model Performance Evaluation\n",
        "score_rfc_tuned = accuracy_score(y_test, y_pred_rfc_tuned)\n",
        "print(\"Test Seti DoÄŸruluÄŸu:\", score_rfc_tuned)\n",
        "print(\"Classification Report:\")\n",
        "classification_report_rfc_tuned = classification_report(y_test, y_pred_rfc_tuned)\n",
        "print(classification_report_rfc_tuned)\n",
        "print(\"Confusion Matrix:\")\n",
        "confusion_matrix_rfc_tuned = confusion_matrix(y_test, y_pred_rfc_tuned)\n",
        "print(confusion_matrix_rfc_tuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1_jK6-al0xv"
      },
      "source": [
        "## SVM with RBF\n",
        "\n",
        "* Data is non-linear so, RBF is neceessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF9O6pBVl0xw"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# SVM modeli RBF kernel ile oluÅŸturma ve eÄŸitme\n",
        "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "\n",
        "# Tahminler yapma\n",
        "y_pred_svm = svm_rbf.predict(X_test)\n",
        "\n",
        "# Model performansÄ±nÄ± deÄŸerlendirme\n",
        "classification_report_svm = classification_report(y_test, y_pred_svm)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_svm)\n",
        "confusion_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLHYgDk4l0xw"
      },
      "source": [
        "### Hyperparameter Tuning for SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-PdoOZql0xx"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],         # Regularization parameter\n",
        "    'gamma': [1, 0.1, 0.01, 0.001], # RBF kernel iÃ§in gamma\n",
        "    'kernel': ['rbf']               # Sadece RBF kernel\n",
        "}\n",
        "\n",
        "best_svm_model_file = os.path.join('../Models', 'best_svm_model.pkl')\n",
        "\n",
        "#Model Check\n",
        "if os.path.exists(best_svm_model_file):\n",
        "    best_svm_model = joblib.load(best_svm_model_file)\n",
        "else:\n",
        "    print(\"Training has started...\")\n",
        "    grid = GridSearchCV(\n",
        "        SVC(random_state=42),\n",
        "        param_grid,\n",
        "        refit=True,\n",
        "        verbose=2,\n",
        "        cv=3\n",
        "    )\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    #Saving the best model\n",
        "    best_svm_model = grid.best_estimator_\n",
        "    joblib.dump(best_svm_model, best_svm_model_file)\n",
        "\n",
        "if 'grid' in locals():\n",
        "    print(\"Best Parameters:\", grid.best_params_)\n",
        "    print(\"Best Cross-Validation Score:\", grid.best_score_)\n",
        "\n",
        "# Test seti Ã¼zerinde tahminler yapma\n",
        "y_pred_svm_tuned = best_svm_model.predict(X_test)\n",
        "\n",
        "# Model performansÄ±nÄ± deÄŸerlendirme\n",
        "score_svm_tuned = accuracy_score(y_test, y_pred_svm_tuned)\n",
        "classification_report_svm_tuned = classification_report(y_test, y_pred_svm_tuned)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report_svm_tuned)\n",
        "confusion_matrix_svm_tuned = confusion_matrix(y_test, y_pred_svm_tuned)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix_svm_tuned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fP2rcCpl0xx"
      },
      "outputs": [],
      "source": [
        "# En iyi parametreleri ve en iyi skoru yazdÄ±rma\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Cross-Validation Score:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFeyqrzLl0xy"
      },
      "outputs": [],
      "source": [
        "# Model performansÄ±nÄ± deÄŸerlendirme\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm_tuned))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm_tuned))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcFiKypSl0xz"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTLqYqxDl0xz"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_clf = XGBClassifier(random_state=42)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "\n",
        "score_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Accuracy: \", score_xgb)\n",
        "print(\"---------------------------------------\")\n",
        "classification_report_xgb = classification_report(y_test, y_pred_xgb)\n",
        "print(\"Classification Report: \")\n",
        "print(classification_report_xgb)\n",
        "print(\"---------------------------------------\")\n",
        "confusion_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(confusion_matrix_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoX418S4l0x0"
      },
      "source": [
        "### Hyperparameter Tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQhkIn87l0x1"
      },
      "outputs": [],
      "source": [
        "best_xgb_model_file = os.path.join('../Models', 'best_xgb_model.pkl')\n",
        "\n",
        "#Model Check\n",
        "if os.path.exists(best_xgb_model_file):\n",
        "    best_xgb_model = joblib.load(best_xgb_model_file)\n",
        "else:\n",
        "    print(\"Training has started...\")\n",
        "\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'max_depth': [3, 5, 7],\n",
        "        'learning_rate': [0.01, 0.1, 0.2],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "    }\n",
        "\n",
        "    # Grid Search Time\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=XGBClassifier(random_state=42),\n",
        "        param_grid=param_grid,\n",
        "        scoring='accuracy',\n",
        "        cv=5,\n",
        "        verbose=2,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    #Saving the best model\n",
        "    best_xgb_model = grid_search.best_estimator_\n",
        "    joblib.dump(best_xgb_model, best_xgb_model_file)\n",
        "\n",
        "if 'grid_search' in locals():\n",
        "    print(\"Best Parameters:\", grid_search.best_params_)\n",
        "    print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Test seti Ã¼zerinde tahminler yapma\n",
        "y_pred_xgb_tuned = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Model performansÄ±nÄ± deÄŸerlendirme\n",
        "score_xgb_tuned = accuracy_score(y_test, y_pred_xgb_tuned)\n",
        "print(\"Classification Report:\")\n",
        "print(\"-----------------------------------------\")\n",
        "classification_report_xgb_tuned = classification_report(y_test, y_pred_xgb_tuned)\n",
        "print(classification_report_xgb_tuned)\n",
        "print(\"-----------------------------------------\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"-----------------------------------------\")\n",
        "confusion_matrix_xgb_tuned = confusion_matrix(y_test, y_pred_xgb_tuned)\n",
        "print(confusion_matrix_xgb_tuned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaKBSUFal0x2"
      },
      "source": [
        "# Metric Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxbwvL2Ml0x2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Classification report string'lerini tanÄ±mlama\n",
        "classification_report_rfc_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.43      0.43      0.43      4714\\n           1       0.42      0.43      0.43      4509\\n           2       0.43      0.43      0.43      4652\\n\\n    accuracy                           0.43     13875\\n   macro avg       0.43      0.43      0.43     13875\\nweighted avg       0.43      0.43      0.43     13875\\n'\n",
        "\n",
        "classification_report_svm_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.43      0.45      0.44      4714\\n           1       0.42      0.41      0.42      4509\\n           2       0.43      0.42      0.43      4652\\n\\n    accuracy                           0.43     13875\\n   macro avg       0.43      0.43      0.43     13875\\nweighted avg       0.43      0.43      0.43     13875\\n'\n",
        "\n",
        "classification_report_xgb_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.39      0.40      0.39      4714\\n           1       0.38      0.39      0.38      4509\\n           2       0.38      0.37      0.38      4652\\n\\n    accuracy                           0.38     13875\\n   macro avg       0.38      0.38      0.38     13875\\nweighted avg       0.38      0.38      0.38     13875\\n'\n",
        "\n",
        "classification_report_logreg = '              precision    recall  f1-score   support\\n\\n           0       0.34      0.28      0.31      4714\\n           1       0.32      0.37      0.34      4509\\n           2       0.34      0.36      0.35      4652\\n\\n    accuracy                           0.34     13875\\n   macro avg       0.34      0.34      0.33     13875\\nweighted avg       0.34      0.34      0.33     13875\\n'\n",
        "\n",
        "# RaporlarÄ± bir dictionary olarak saklayalÄ±m\n",
        "classification_reports = {\n",
        "    \"RFC Tuned\": classification_report_rfc_tuned,\n",
        "    \"SVM Tuned\": classification_report_svm_tuned,\n",
        "    \"XGB Tuned\": classification_report_xgb_tuned,\n",
        "    \"LogReg\": classification_report_logreg\n",
        "}\n",
        "\n",
        "# Her raporu iÅŸleyerek anlamlÄ± bir yapÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rme\n",
        "processed_reports = {}\n",
        "for algo_name, report_text in classification_reports.items():\n",
        "    # Metin raporunu DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "    df = pd.read_fwf(StringIO(report_text), skiprows=1)\n",
        "    df.columns = ['class', 'precision', 'recall', 'f1-score', 'support']\n",
        "\n",
        "    # Sadece \"macro avg\" satÄ±rÄ±nÄ± Ã§ekiyoruz\n",
        "    macro_avg_row = df[df['class'] == 'macro avg']\n",
        "    processed_reports[algo_name] = macro_avg_row[['precision', 'recall', 'f1-score']].iloc[0]\n",
        "\n",
        "# GÃ¶rselleÅŸtirme iÃ§in hazÄ±r veri oluÅŸturma\n",
        "algorithms = list(processed_reports.keys())\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "data = {metric: [processed_reports[algo][metric] for algo in algorithms] for metric in metrics}\n",
        "\n",
        "# SubplotlarÄ± oluÅŸturma\n",
        "fig, axes = plt.subplots(1, len(metrics), figsize=(18, 6), sharey=True)\n",
        "\n",
        "colors = ['blue', 'green', 'red', 'orange']  # Her algoritma iÃ§in bir renk\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    axes[i].bar(algorithms, data[metric], color=colors)\n",
        "    axes[i].set_title(metric.capitalize())\n",
        "    axes[i].set_ylabel('Score')\n",
        "    axes[i].set_ylim(0, 1)  # Skor aralÄ±ÄŸÄ±\n",
        "    axes[i].set_xticks(range(len(algorithms)))\n",
        "    axes[i].set_xticklabels(algorithms, rotation=45)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkLWc9sql0x3"
      },
      "outputs": [],
      "source": [
        "score_rfc_tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ia55PzEl0x5"
      },
      "outputs": [],
      "source": [
        "score_xgb_tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN0_Xaxgl0x5"
      },
      "outputs": [],
      "source": [
        "score_svm_tuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBRFe_t5l0x6"
      },
      "outputs": [],
      "source": [
        "score_logreg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVkl3WeBl0x7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Classification report string'lerini tanÄ±mlama\n",
        "classification_report_rfc_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.43      0.43      0.43      4714\\n           1       0.42      0.43      0.43      4509\\n           2       0.43      0.43      0.43      4652\\n\\n    accuracy                           0.43     13875\\n   macro avg       0.43      0.43      0.43     13875\\nweighted avg       0.43      0.43      0.43     13875\\n'\n",
        "\n",
        "classification_report_svm_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.43      0.45      0.44      4714\\n           1       0.42      0.41      0.42      4509\\n           2       0.43      0.42      0.43      4652\\n\\n    accuracy                           0.43     13875\\n   macro avg       0.43      0.43      0.43     13875\\nweighted avg       0.43      0.43      0.43     13875\\n'\n",
        "\n",
        "classification_report_xgb_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.39      0.40      0.39      4714\\n           1       0.38      0.39      0.38      4509\\n           2       0.38      0.37      0.38      4652\\n\\n    accuracy                           0.38     13875\\n   macro avg       0.38      0.38      0.38     13875\\nweighted avg       0.38      0.38      0.38     13875\\n'\n",
        "\n",
        "classification_report_logreg = '              precision    recall  f1-score   support\\n\\n           0       0.34      0.28      0.31      4714\\n           1       0.32      0.37      0.34      4509\\n           2       0.34      0.36      0.35      4652\\n\\n    accuracy                           0.34     13875\\n   macro avg       0.34      0.34      0.33     13875\\nweighted avg       0.34      0.34      0.33     13875\\n'\n",
        "\n",
        "# RaporlarÄ± bir dictionary olarak saklayalÄ±m\n",
        "classification_reports = {\n",
        "    \"RFC Tuned\": classification_report_rfc_tuned,\n",
        "    \"SVM Tuned\": classification_report_svm_tuned,\n",
        "    \"XGB Tuned\": classification_report_xgb_tuned,\n",
        "    \"LogReg\": classification_report_logreg\n",
        "}\n",
        "\n",
        "# Her raporu iÅŸleyerek anlamlÄ± bir yapÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rme\n",
        "processed_reports = {}\n",
        "for algo_name, report_text in classification_reports.items():\n",
        "    df = pd.read_fwf(StringIO(report_text), skiprows=1)\n",
        "    df.columns = ['class', 'precision', 'recall', 'f1-score', 'support']\n",
        "    macro_avg_row = df[df['class'] == 'macro avg']\n",
        "    processed_reports[algo_name] = macro_avg_row[['precision', 'recall', 'f1-score']].iloc[0]\n",
        "\n",
        "# Ek olarak accuracy skorlarÄ±nÄ± tanÄ±mlama\n",
        "accuracy_scores = {\n",
        "    \"RFC Tuned\": 0.42897297297297273,\n",
        "    \"XGB Tuned\": 0.3842162162162162,\n",
        "    \"SVM Tuned\": 0.428036036036036,\n",
        "    \"LogReg\": 0.3354954954954955\n",
        "}\n",
        "\n",
        "# GÃ¶rselleÅŸtirme iÃ§in veri hazÄ±rlama\n",
        "algorithms = list(processed_reports.keys())\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "data = {metric: [processed_reports[algo][metric] for algo in algorithms] for metric in metrics}\n",
        "\n",
        "# SubplotlarÄ± oluÅŸturma (4 grafik: precision, recall, f1-score ve accuracy)\n",
        "fig, axes = plt.subplots(1, len(metrics) + 1, figsize=(24, 6), sharey=False)\n",
        "\n",
        "colors = ['blue', 'green', 'red', 'orange']  # Her algoritma iÃ§in renk\n",
        "\n",
        "# Ä°lk 3 grafiÄŸi Ã§izme (precision, recall, f1-score)\n",
        "for i, metric in enumerate(metrics):\n",
        "    axes[i].bar(algorithms, data[metric], color=colors)\n",
        "    axes[i].set_title(metric.capitalize())\n",
        "    axes[i].set_ylabel('Score')\n",
        "    axes[i].set_ylim(0, 1)\n",
        "    axes[i].set_xticks(range(len(algorithms)))\n",
        "    axes[i].set_xticklabels(algorithms, rotation=45)\n",
        "\n",
        "# 4. grafik olarak accuracy grafiÄŸini ekleme\n",
        "axes[3].bar(algorithms, list(accuracy_scores.values()), color=colors)\n",
        "axes[3].set_title(\"Accuracy\")\n",
        "axes[3].set_ylabel('Score')\n",
        "axes[3].set_ylim(0, 1)\n",
        "axes[3].set_xticks(range(len(algorithms)))\n",
        "axes[3].set_xticklabels(algorithms, rotation=45)\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjJAyMl0l0x8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "# Classification report string'lerini tanÄ±mlama\n",
        "classification_report_rfc_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.43      0.43      0.43      4714\\n           1       0.42      0.43      0.43      4509\\n           2       0.43      0.43      0.43      4652\\n\\n    accuracy                           0.43     13875\\n   macro avg       0.43      0.43      0.43     13875\\nweighted avg       0.43      0.43      0.43     13875\\n'\n",
        "\n",
        "classification_report_svm_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.43      0.45      0.44      4714\\n           1       0.42      0.41      0.42      4509\\n           2       0.43      0.42      0.43      4652\\n\\n    accuracy                           0.43     13875\\n   macro avg       0.43      0.43      0.43     13875\\nweighted avg       0.43      0.43      0.43     13875\\n'\n",
        "\n",
        "classification_report_xgb_tuned = '              precision    recall  f1-score   support\\n\\n           0       0.39      0.40      0.39      4714\\n           1       0.38      0.39      0.38      4509\\n           2       0.38      0.37      0.38      4652\\n\\n    accuracy                           0.38     13875\\n   macro avg       0.38      0.38      0.38     13875\\nweighted avg       0.38      0.38      0.38     13875\\n'\n",
        "\n",
        "classification_report_logreg = '              precision    recall  f1-score   support\\n\\n           0       0.34      0.28      0.31      4714\\n           1       0.32      0.37      0.34      4509\\n           2       0.34      0.36      0.35      4652\\n\\n    accuracy                           0.34     13875\\n   macro avg       0.34      0.34      0.33     13875\\nweighted avg       0.34      0.34      0.33     13875\\n'\n",
        "\n",
        "# RaporlarÄ± bir dictionary olarak saklayalÄ±m\n",
        "classification_reports = {\n",
        "    \"RFC Tuned\": classification_report_rfc_tuned,\n",
        "    \"SVM Tuned\": classification_report_svm_tuned,\n",
        "    \"XGB Tuned\": classification_report_xgb_tuned,\n",
        "    \"LogReg\": classification_report_logreg\n",
        "}\n",
        "\n",
        "# Her raporu iÅŸleyerek anlamlÄ± bir yapÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rme\n",
        "processed_reports = {}\n",
        "for algo_name, report_text in classification_reports.items():\n",
        "    df = pd.read_fwf(StringIO(report_text), skiprows=1)\n",
        "    df.columns = ['class', 'precision', 'recall', 'f1-score', 'support']\n",
        "    macro_avg_row = df[df['class'] == 'macro avg']\n",
        "    processed_reports[algo_name] = macro_avg_row[['precision', 'recall', 'f1-score']].iloc[0]\n",
        "\n",
        "# Ek olarak accuracy skorlarÄ±nÄ± tanÄ±mlama\n",
        "accuracy_scores = {\n",
        "    \"RFC Tuned\": 0.42897297297297273,\n",
        "    \"XGB Tuned\": 0.3842162162162162,\n",
        "    \"SVM Tuned\": 0.428036036036036,\n",
        "    \"LogReg\": 0.3354954954954955\n",
        "}\n",
        "\n",
        "# GÃ¶rselleÅŸtirme iÃ§in veri hazÄ±rlama\n",
        "algorithms = list(processed_reports.keys())\n",
        "metrics = ['precision', 'recall', 'f1-score']\n",
        "data = {metric: [processed_reports[algo][metric] for algo in algorithms] for metric in metrics}\n",
        "\n",
        "# SubplotlarÄ± oluÅŸturma (2 satÄ±r, 2 sÃ¼tun)\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "axes = axes.flatten()  # 2x2 eksenleri tek bir listeye dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "\n",
        "colors = ['blue', 'green', 'red', 'orange']  # Her algoritma iÃ§in renk\n",
        "\n",
        "# Ä°lk 3 grafiÄŸi Ã§izme (precision, recall, f1-score)\n",
        "for i, metric in enumerate(metrics):\n",
        "    axes[i].bar(algorithms, data[metric], color=colors)\n",
        "    axes[i].set_title(f\"{metric.capitalize()} Scores\")\n",
        "    axes[i].set_ylabel('Score')\n",
        "    axes[i].set_ylim(0, 1)\n",
        "    axes[i].set_xticklabels(algorithms, rotation=45)\n",
        "\n",
        "# 4. grafik: Accuracy\n",
        "axes[3].bar(algorithms, list(accuracy_scores.values()), color=colors)\n",
        "axes[3].set_title(\"Accuracy Scores\")\n",
        "axes[3].set_ylabel('Score')\n",
        "axes[3].set_ylim(0, 1)\n",
        "axes[3].set_xticklabels(algorithms, rotation=45)\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}